{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mood Detection using EEG Data\n"
      ],
      "metadata": {
        "id": "UUE3mKs8RoY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2sVrScBnrhF",
        "outputId": "1eea4571-975c-458c-96fb-d925a30272a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (2132, 2549)\n",
            "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
            "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
            "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
            "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
            "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
            "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
            "\n",
            "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
            "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
            "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
            "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
            "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
            "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
            "\n",
            "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
            "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
            "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
            "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
            "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
            "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
            "\n",
            "[5 rows x 2549 columns]\n"
          ]
        }
      ],
      "source": [
        "# ========================\n",
        "# 📦 Import Dependencies\n",
        "# ========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ========================\n",
        "# 📥 Load Dataset\n",
        "# ========================\n",
        "data = pd.read_csv(\"emotions.csv\")\n",
        "print(f\"Dataset shape: {data.shape}\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump\n",
        "# ========================\n",
        "# 🎯 Encode Labels & Scale\n",
        "# ========================\n",
        "def transform_data(data):\n",
        "    # Encode labels to numbers\n",
        "    encoding_map = {'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 2}\n",
        "    data_encoded = data.replace(encoding_map)\n",
        "\n",
        "    # Separate features & labels\n",
        "    X = data_encoded.drop([\"label\"], axis=1).values\n",
        "    y = data_encoded[\"label\"].values\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    y_onehot = to_categorical(y, num_classes=3)\n",
        "\n",
        "    return X_scaled, y_onehot, scaler\n",
        "\n",
        "X, Y, scaler = transform_data(data)\n",
        "\n",
        "# After creating and fitting the scaler in transform_data()\n",
        "X, Y, scaler = transform_data(data)\n",
        "\n",
        "# Save scaler to disk\n",
        "dump(scaler, 'scaler.save')\n",
        "\n",
        "# Shuffle and split dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, Y, test_size=0.1, random_state=42, shuffle=True\n",
        ")\n",
        "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dIUuqiZn8GY",
        "outputId": "2bf1aae6-a02e-4322-b977-85ca182481ad"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2517790881.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data_encoded = data.replace(encoding_map)\n",
            "/tmp/ipython-input-2517790881.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data_encoded = data.replace(encoding_map)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1918, 2548), Test shape: (214, 2548)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Map from index back to label names\n",
        "label_map = {0: 'NEUTRAL', 1: 'POSITIVE', 2: 'NEGATIVE'}\n",
        "\n",
        "# Convert one-hot back to label indices for test set\n",
        "test_labels_idx = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Count samples per label\n",
        "(unique, counts) = np.unique(test_labels_idx, return_counts=True)\n",
        "label_counts = dict(zip(unique, counts))\n",
        "\n",
        "# Print counts\n",
        "print(\"Test set label counts:\")\n",
        "for idx, count in label_counts.items():\n",
        "    print(f\"{label_map[idx]}: {count}\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=[label_map[i] for i in unique], y=counts)\n",
        "plt.title(\"Test Set Samples per Label\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "643DIi-7tOH3",
        "outputId": "03456946-398b-4ab8-e45b-a77648ea2e7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set label counts:\n",
            "NEUTRAL: 635\n",
            "POSITIVE: 647\n",
            "NEGATIVE: 636\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAHWCAYAAABt3aEVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARaFJREFUeJzt3XtclGX+//H3gJzkKCigXxXJM4lZakJamZJ4qkw7aJrH1dbw3HpgtzxgSbqZZuGhVkFLs3DT0i0Nz6aoqWuZmmlh2ipoKuAhQeD+/eGP2SawGBhE7309H495PJjruua+P/c4w7y9ue5rLIZhGAIAAABMwKmiCwAAAAAchXALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAP9jkpKSZLFYdPz48You5bZV+Bzu2bPHYducPHmyLBaLw7YH/K8i3AIolsViKdFt8+bNZd7XlStXNHnyZLu2dfz4cQ0YMEB169aVu7u7goOD9cADD2jSpEmlquHTTz/V5MmTSzy+oKBAS5YsUatWreTv7y9vb281aNBAffv21c6dO0tVA8pX//795eXlVdFlAChnlSq6AAC3pnfffdfm/pIlS5SSklKkvXHjxmXe15UrVzRlyhRJUtu2bf9w/LFjx9SyZUt5eHho4MCBqlOnjk6fPq19+/Zp+vTp1m3Z49NPP1VCQkKJA+6IESOUkJCgxx57TL1791alSpV05MgRffbZZ7rjjjsUERFhdw0AgLIj3AIoVp8+fWzu79y5UykpKUXaK8KsWbN06dIl7d+/XyEhITZ9Z86cKff9Z2RkaO7cuRo8eLDefvttm77Zs2fr7Nmz5V4DijIMQ1evXpWHh0dFlwKgAjEtAUCpFRQUaPbs2brzzjvl7u6uoKAgPffcc7pw4YLNuD179ig6OlpVq1aVh4eHQkNDNXDgQEnXpxdUq1ZNkjRlyhTrdIffO4P6/fffq2bNmkWCrSQFBgYWafvss890//33y9PTU97e3urSpYsOHjxo7e/fv78SEhIk2U7HuJG0tDQZhqHWrVsX6bNYLDY1nD9/Xn/5y18UHh4uLy8v+fj4qFOnTvrqq69sHrd582ZZLBZ9+OGHmjJliv7v//5P3t7eeuKJJ5SVlaWcnByNGjVKgYGB8vLy0oABA5STk1Nk38OGDdPSpUvVsGFDubu7q3nz5tq6desNj8We50mS0tPTNWDAANWsWVNubm6qXr26HnvssT+cv1s4JeCHH35QdHS0PD09VaNGDcXFxckwDJuxJX1d1alTR127dtW6devUokULeXh4aMGCBSU61hv58ccf9fzzz6thw4by8PBQQECAnnzyyRse35UrV/Tcc88pICBAPj4+6tu3b5E6pZI9twAcgzO3AErtueeeU1JSkgYMGKARI0YoLS1Nb731lv79739r+/btcnFx0ZkzZ9ShQwdVq1ZNEyZMkJ+fn44fP66PPvpIklStWjXNmzdPQ4cO1eOPP67u3btLkpo2bXrD/YaEhGj9+vXauHGj2rVr97s1vvvuu+rXr5+io6M1ffp0XblyRfPmzVObNm3073//W3Xq1NFzzz2nU6dOFTvt4kb7l6Tk5GQ9+eSTqly58g3H/vDDD1q1apWefPJJhYaGKiMjQwsWLNCDDz6oQ4cOqUaNGjbj4+Pj5eHhoQkTJujYsWN688035eLiIicnJ124cEGTJ0/Wzp07lZSUpNDQUE2cONHm8Vu2bNEHH3ygESNGyM3NTXPnzlXHjh21e/duNWnSpEzPkyT16NFDBw8e1PDhw1WnTh2dOXNGKSkpOnHihHXMjeTn56tjx46KiIjQjBkztHbtWk2aNEl5eXmKi4uzjivJ66rQkSNH1KtXLz333HMaPHiwGjZs+Ls1/JEvv/xSO3bsUM+ePVWzZk0dP35c8+bNU9u2bXXo0KEi/9bDhg2Tn5+fJk+erCNHjmjevHn68ccfrf9Zsee5BeAgBgCUQExMjPHrXxnbtm0zJBlLly61Gbd27Vqb9pUrVxqSjC+//PKG2z579qwhyZg0aVKJavnmm28MDw8PQ5LRrFkzY+TIkcaqVauMy5cv24y7ePGi4efnZwwePNimPT093fD19bVp/+3x/ZG+ffsakowqVaoYjz/+uPHaa68Zhw8fLjLu6tWrRn5+vk1bWlqa4ebmZsTFxVnbNm3aZEgymjRpYuTm5lrbe/XqZVgsFqNTp04224iMjDRCQkJs2iQZkow9e/ZY23788UfD3d3dePzxx61tiYmJhiQjLS3NMIySP08XLlwwJBl///vfS/AM2erXr58hyRg+fLi1raCgwOjSpYvh6upqnD171jCMkr+uDMMwQkJCDEnG2rVrS1yDp6fn7465cuVKkbbU1FRDkrFkyRJrW+Fz2Lx5c5t/rxkzZhiSjI8//tgwDPteg5MmTbLrNQigeExLAFAqycnJ8vX11cMPP6yff/7ZemvevLm8vLy0adMmSZKfn58kac2aNbp27ZpD9n3nnXdq//796tOnj44fP6433nhD3bp1U1BQkN555x3ruJSUFGVmZqpXr142NTo7O6tVq1bWGksjMTFRb731lkJDQ7Vy5Ur95S9/UePGjdW+fXv95z//sY5zc3OTk9P1X7X5+fk6d+6cvLy81LBhQ+3bt6/Idvv27WtzZrJVq1YyDMM6jePX7SdPnlReXp5Ne2RkpJo3b269X7t2bT322GNat26d8vPziz2Wkj5PHh4ecnV11ebNm4v903tJDBs2zPpz4TSK3NxcrV+/XlLJX1eFQkNDFR0dXapaivPr+brXrl3TuXPnVK9ePfn5+RX77zVkyBCbf6+hQ4eqUqVK+vTTTyWV72sQQPGYlgCgVI4ePaqsrKxi57hK/72w68EHH1SPHj00ZcoUzZo1S23btlW3bt30zDPPyM3NrdT7b9Cggd59913l5+fr0KFDWrNmjWbMmKEhQ4YoNDRUUVFROnr0qCTdcOqCj49Pqffv5OSkmJgYxcTE6Ny5c9q+fbvmz5+vzz77TD179tS2bdskXZ8/+sYbb2ju3LlKS0uzCZgBAQFFtlu7dm2b+76+vpKkWrVqFWkvKChQVlaWzXbq169fZJsNGjTQlStXdPbsWQUHBxfpL+nz5ObmpunTp+uFF15QUFCQIiIi1LVrV/Xt27fY7f6Wk5OT7rjjjiK1SbLOaS3p66pQaGjoH+7XHr/88ovi4+OVmJio//znPzbzgbOysoqM/+3z7eXlperVq9scj1Q+r0EAxSPcAiiVgoICBQYGaunSpcX2F14kZrFYtGLFCu3cuVOrV6/WunXrNHDgQM2cOVM7d+4s87qjzs7OCg8PV3h4uCIjI/XQQw9p6dKlioqKUkFBgaTrcx6LC1+VKjnmV2BAQIAeffRRPfroo2rbtq22bNmiH3/8USEhIZo2bZpeeuklDRw4UFOnTpW/v7+cnJw0atQoa32/PZ4bHWdxjN9cjFUa9jxPo0aN0iOPPKJVq1Zp3bp1eumllxQfH6+NGzfq7rvvdkgtJXldFXL0ygjDhw9XYmKiRo0apcjISPn6+spisahnz57F/nv9kZv1GgTwX7yrAJRK3bp1tX79erVu3bpEASMiIkIRERF65ZVXtGzZMvXu3VvLly/Xn/70J4d9K1OLFi0kSadPn7bWKF1fQSEqKup3H+vIGrZs2aLTp08rJCREK1as0EMPPaSFCxfajMvMzFTVqlUdss9fKzxT+GvfffedKleuXCQYFrLneSoc/8ILL+iFF17Q0aNH1axZM82cOVPvvffe7z6uoKBAP/zwg/VsbWFtkqwXVdn7unK0FStWqF+/fpo5c6a17erVq8rMzCx2/NGjR/XQQw9Z71+6dEmnT59W586dJdn/3AIoO+bcAiiVp556Svn5+Zo6dWqRvry8PGsYuHDhQpGzi82aNZMk61JWhVeg3yhA/Na2bduKnb9bOM+x8Ir56Oho+fj4aNq0acWO//V6tJ6eniWuIT09XYcOHSrSnpubqw0bNsjJyUn16tWTdP2M62+PPzk52WZeriOlpqbazA09efKkPv74Y3Xo0OGGZ39L+jxduXJFV69etemrW7euvL29iyxLdiNvvfWW9WfDMPTWW2/JxcVF7du3l1Ty11V5Ke7f680337zhfOW3337b5jmbN2+e8vLy1KlTJ0n2vQYBOAZnbgGUyoMPPqjnnntO8fHx2r9/vzp06CAXFxcdPXpUycnJeuONN/TEE09o8eLFmjt3rh5//HHVrVtXFy9e1DvvvCMfHx/r2S0PDw+FhYXpgw8+UIMGDeTv768mTZrccOmq6dOna+/everevbt1ybB9+/ZpyZIl8vf316hRoyRdn884b948Pfvss7rnnnvUs2dPVatWTSdOnNC//vUvtW7d2hq2Ci/CGjFihKKjo+Xs7KyePXsWu/+ffvpJ9957r9q1a6f27dsrODhYZ86c0fvvv6+vvvpKo0aNsp6V7dq1q+Li4jRgwADdd999OnDggJYuXVpk7qmjNGnSRNHR0TZLgUn63W9tK+nz9N1336l9+/Z66qmnFBYWpkqVKmnlypXKyMi44XP1a+7u7lq7dq369eunVq1a6bPPPtO//vUv/fWvf7WeVS7p66q0rl27ppdffrlIu7+/v55//nl17dpV7777rnx9fRUWFqbU1FStX7++2PnR0vX/0BQ+J0eOHNHcuXPVpk0bPfroo3Y9twAcqAJXagBwG7nRUllvv/220bx5c8PDw8Pw9vY2wsPDjXHjxhmnTp0yDMMw9u3bZ/Tq1cuoXbu24ebmZgQGBhpdu3a1Wa7KMAxjx44dRvPmzQ1XV9c/XBZs+/btRkxMjNGkSRPD19fXcHFxMWrXrm3079/f+P7774uM37RpkxEdHW34+voa7u7uRt26dY3+/fvb1JCXl2cMHz7cqFatmmGxWH53Sabs7GzjjTfeMKKjo42aNWsaLi4uhre3txEZGWm88847RkFBgXXs1atXjRdeeMGoXr264eHhYbRu3dpITU01HnzwQePBBx+0qVGSkZycbLOvwiWnfruUWuGyUYVLaBnG9aXAYmJijPfee8+oX7++4ebmZtx9993Gpk2bit1m4VJgJX2efv75ZyMmJsZo1KiR4enpafj6+hqtWrUyPvzwwxs+V4UKl+H6/vvvjQ4dOhiVK1c2goKCjEmTJhVZKs0w/vh1ZRjXlwLr0qXLH+771zXo/y+X9ttb3bp1DcO4vtzZgAEDjKpVqxpeXl5GdHS08e233xohISFGv379ijyHW7ZsMYYMGWJUqVLF8PLyMnr37m2cO3euyL5L8hpkKTDAMSyG4YCrEQAAFc5isSgmJuaWPBPYv39/rVixQpcuXaroUgCYHHNuAQAAYBqEWwAAAJgG4RYAAACmwZxbAAAAmAZnbgEAAGAahFsAAACYBl/ioOtfCXnq1Cl5e3s77Cs4AQAA4DiGYejixYuqUaOGnJxufH6WcCvp1KlTqlWrVkWXAQAAgD9w8uRJ1axZ84b9hFtJ3t7ekq4/WT4+PhVcDQAAAH4rOztbtWrVsua2GyHcStapCD4+PoRbAACAW9gfTSHlgjIAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGlUqugCAODXmo9dUtElADb2/r1vRZcAwA6cuQUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpsFoCAAAmwEojuNVU1EojhNtywi8Z3IpY0ggAYHZMSwAAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmEaFh9v//Oc/6tOnjwICAuTh4aHw8HDt2bPH2m8YhiZOnKjq1avLw8NDUVFROnr0qM02zp8/r969e8vHx0d+fn4aNGiQLl26dLMPBQAAABWsQsPthQsX1Lp1a7m4uOizzz7ToUOHNHPmTFWpUsU6ZsaMGZozZ47mz5+vXbt2ydPTU9HR0bp69ap1TO/evXXw4EGlpKRozZo12rp1q4YMGVIRhwQAAIAKVKkidz59+nTVqlVLiYmJ1rbQ0FDrz4ZhaPbs2XrxxRf12GOPSZKWLFmioKAgrVq1Sj179tThw4e1du1affnll2rRooUk6c0331Tnzp312muvqUaNGjf3oAAAAFBhKvTM7SeffKIWLVroySefVGBgoO6++26988471v60tDSlp6crKirK2ubr66tWrVopNTVVkpSamio/Pz9rsJWkqKgoOTk5adeuXcXuNycnR9nZ2TY3AAAA3P4qNNz+8MMPmjdvnurXr69169Zp6NChGjFihBYvXixJSk9PlyQFBQXZPC4oKMjal56ersDAQJv+SpUqyd/f3zrmt+Lj4+Xr62u91apVy9GHBgAAgApQoeG2oKBA99xzj6ZNm6a7775bQ4YM0eDBgzV//vxy3W9sbKyysrKst5MnT5br/gAAAHBzVGi4rV69usLCwmzaGjdurBMnTkiSgoODJUkZGRk2YzIyMqx9wcHBOnPmjE1/Xl6ezp8/bx3zW25ubvLx8bG5AQAA4PZXoeG2devWOnLkiE3bd999p5CQEEnXLy4LDg7Whg0brP3Z2dnatWuXIiMjJUmRkZHKzMzU3r17rWM2btyogoICtWrV6iYcBQAAAG4VFbpawujRo3Xfffdp2rRpeuqpp7R79269/fbbevvttyVJFotFo0aN0ssvv6z69esrNDRUL730kmrUqKFu3bpJun6mt2PHjtbpDNeuXdOwYcPUs2dPVkoAAAD4H1Oh4bZly5ZauXKlYmNjFRcXp9DQUM2ePVu9e/e2jhk3bpwuX76sIUOGKDMzU23atNHatWvl7u5uHbN06VINGzZM7du3l5OTk3r06KE5c+ZUxCEBAACgAlVouJWkrl27qmvXrjfst1gsiouLU1xc3A3H+Pv7a9myZeVRHgAAAG4jFf71uwAAAICjEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpVGi4nTx5siwWi82tUaNG1v6rV68qJiZGAQEB8vLyUo8ePZSRkWGzjRMnTqhLly6qXLmyAgMDNXbsWOXl5d3sQwEAAMAtoFJFF3DnnXdq/fr11vuVKv23pNGjR+tf//qXkpOT5evrq2HDhql79+7avn27JCk/P19dunRRcHCwduzYodOnT6tv375ycXHRtGnTbvqxAAAAoGJVeLitVKmSgoODi7RnZWVp4cKFWrZsmdq1aydJSkxMVOPGjbVz505FRETo888/16FDh7R+/XoFBQWpWbNmmjp1qsaPH6/JkyfL1dX1Zh8OAAAAKlCFz7k9evSoatSooTvuuEO9e/fWiRMnJEl79+7VtWvXFBUVZR3bqFEj1a5dW6mpqZKk1NRUhYeHKygoyDomOjpa2dnZOnjw4A33mZOTo+zsbJsbAAAAbn8VGm5btWqlpKQkrV27VvPmzVNaWpruv/9+Xbx4Uenp6XJ1dZWfn5/NY4KCgpSeni5JSk9Ptwm2hf2FfTcSHx8vX19f661WrVqOPTAAAABUiAqdltCpUyfrz02bNlWrVq0UEhKiDz/8UB4eHuW239jYWI0ZM8Z6Pzs7m4ALAABgAhU+LeHX/Pz81KBBAx07dkzBwcHKzc1VZmamzZiMjAzrHN3g4OAiqycU3i9uHm8hNzc3+fj42NwAAABw+7ulwu2lS5f0/fffq3r16mrevLlcXFy0YcMGa/+RI0d04sQJRUZGSpIiIyN14MABnTlzxjomJSVFPj4+CgsLu+n1AwAAoGJV6LSEv/zlL3rkkUcUEhKiU6dOadKkSXJ2dlavXr3k6+urQYMGacyYMfL395ePj4+GDx+uyMhIRURESJI6dOigsLAwPfvss5oxY4bS09P14osvKiYmRm5ubhV5aAAAAKgAFRpuf/rpJ/Xq1Uvnzp1TtWrV1KZNG+3cuVPVqlWTJM2aNUtOTk7q0aOHcnJyFB0drblz51of7+zsrDVr1mjo0KGKjIyUp6en+vXrp7i4uIo6JAAAAFSgCg23y5cv/91+d3d3JSQkKCEh4YZjQkJC9Omnnzq6NAAAANyGbqk5twAAAEBZEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBp2B1uT548qZ9++sl6f/fu3Ro1apTefvtthxYGAAAA2MvucPvMM89o06ZNkqT09HQ9/PDD2r17t/72t78pLi7O4QUCAAAAJWV3uP3mm2907733SpI+/PBDNWnSRDt27NDSpUuVlJTk6PoAAACAErM73F67dk1ubm6SpPXr1+vRRx+VJDVq1EinT592bHUAAACAHewOt3feeafmz5+vbdu2KSUlRR07dpQknTp1SgEBAQ4vEAAAACgpu8Pt9OnTtWDBArVt21a9evXSXXfdJUn65JNPrNMVAAAAgIpQyd4HtG3bVj///LOys7NVpUoVa/uQIUNUuXJlhxYHAAAA2KNU69wahqG9e/dqwYIFunjxoiTJ1dWVcAsAAIAKZfeZ2x9//FEdO3bUiRMnlJOTo4cfflje3t6aPn26cnJyNH/+/PKoEwAAAPhDdp+5HTlypFq0aKELFy7Iw8PD2v74449rw4YNDi0OAAAAsIfdZ263bdumHTt2yNXV1aa9Tp06+s9//uOwwgAAAAB72X3mtqCgQPn5+UXaf/rpJ3l7ezukKAAAAKA07A63HTp00OzZs633LRaLLl26pEmTJqlz586OrA0AAACwi93TEmbOnKno6GiFhYXp6tWreuaZZ3T06FFVrVpV77//fnnUCAAAAJSI3eG2Zs2a+uqrr7R8+XJ9/fXXunTpkgYNGqTevXvbXGAGAAAA3Gx2h1tJqlSpkvr06ePoWgAAAIAyKVG4/eSTT0q8wUcffbTUxQAAAABlUaJw261btxJtzGKxFLuSAgAAAHAzlCjcFhQUlHcdAAAAQJnZvRQYAAAAcKsqVbjdsGGDunbtqrp166pu3brq2rWr1q9f7+jaAAAAALvYHW7nzp2rjh07ytvbWyNHjtTIkSPl4+Ojzp07KyEhoTxqBAAAAErE7qXApk2bplmzZmnYsGHWthEjRqh169aaNm2aYmJiHFogAAAAUFJ2n7nNzMxUx44di7R36NBBWVlZDikKAAAAKA27w+2jjz6qlStXFmn/+OOP1bVrV4cUBQAAAJSG3dMSwsLC9Morr2jz5s2KjIyUJO3cuVPbt2/XCy+8oDlz5ljHjhgxwnGVAgAAAH/A7nC7cOFCValSRYcOHdKhQ4es7X5+flq4cKH1vsViIdwCAADgprI73KalpZVHHQAAAECZ8SUOAAAAMA27w61hGEpOTtbzzz+vJ554Qt27d7e5ldarr74qi8WiUaNGWduuXr2qmJgYBQQEyMvLSz169FBGRobN406cOKEuXbqocuXKCgwM1NixY5WXl1fqOgAAAHD7sjvcjho1Ss8++6zS0tLk5eUlX19fm1tpfPnll1qwYIGaNm1q0z569GitXr1aycnJ2rJli06dOmUToPPz89WlSxfl5uZqx44dWrx4sZKSkjRx4sRS1QEAAIDbm91zbt9991199NFH6ty5s0MKuHTpknr37q133nlHL7/8srU9KytLCxcu1LJly9SuXTtJUmJioho3bqydO3cqIiJCn3/+uQ4dOqT169crKChIzZo109SpUzV+/HhNnjxZrq6uDqkRAAAAtwe7z9z6+vrqjjvucFgBMTEx6tKli6Kiomza9+7dq2vXrtm0N2rUSLVr11ZqaqokKTU1VeHh4QoKCrKOiY6OVnZ2tg4ePHjDfebk5Cg7O9vmBgAAgNuf3eF28uTJmjJlin755Zcy73z58uXat2+f4uPji/Slp6fL1dVVfn5+Nu1BQUFKT0+3jvl1sC3sL+y7kfj4eJupFLVq1SrjkQAAAOBWYPe0hKeeekrvv/++AgMDVadOHbm4uNj079u3r0TbOXnypEaOHKmUlBS5u7vbW0aZxMbGasyYMdb72dnZBFwAAAATsDvc9uvXT3v37lWfPn0UFBQki8VSqh3v3btXZ86c0T333GNty8/P19atW/XWW29p3bp1ys3NVWZmps3Z24yMDAUHB0uSgoODtXv3bpvtFq6mUDimOG5ubnJzcytV3QAAALh12R1u//Wvf2ndunVq06ZNmXbcvn17HThwwKZtwIABatSokcaPH69atWrJxcVFGzZsUI8ePSRJR44c0YkTJ6xf+xsZGalXXnlFZ86cUWBgoCQpJSVFPj4+CgsLK1N9AAAAuP3YHW5r1aolHx+fMu/Y29tbTZo0sWnz9PRUQECAtX3QoEEaM2aM/P395ePjo+HDhysyMlIRERGSpA4dOigsLEzPPvusZsyYofT0dL344ouKiYnhzCwAAMD/ILsvKJs5c6bGjRun48ePl0M5tmbNmqWuXbuqR48eeuCBBxQcHKyPPvrI2u/s7Kw1a9bI2dlZkZGR6tOnj/r27au4uLhyrw0AAAC3HrvP3Pbp00dXrlxR3bp1Vbly5SIXlJ0/f77UxWzevNnmvru7uxISEpSQkHDDx4SEhOjTTz8t9T4BAABgHnaH29mzZ5dDGQAAAEDZlWq1BAAAAOBWZHe4/bWrV68qNzfXps0RF5sBAAAApWH3BWWXL1/WsGHDFBgYKE9PT1WpUsXmBgAAAFQUu8PtuHHjtHHjRs2bN09ubm76xz/+oSlTpqhGjRpasmRJedQIAAAAlIjd0xJWr16tJUuWqG3bthowYIDuv/9+1atXTyEhIVq6dKl69+5dHnUCAAAAf8juM7fnz5/XHXfcIen6/NrCpb/atGmjrVu3OrY6AAAAwA52h9s77rhDaWlpkqRGjRrpww8/lHT9jK6fn59DiwMAAADsYXe4HTBggL766itJ0oQJE5SQkCB3d3eNHj1aY8eOdXiBAAAAQEnZPed29OjR1p+joqJ0+PBh7du3T/Xq1VPTpk0dWhwAAABgjzKtcytJderUUZ06dRxQCgAAAFA2JZ6WkJqaqjVr1ti0LVmyRKGhoQoMDNSQIUOUk5Pj8AIBAACAkipxuI2Li9PBgwet9w8cOKBBgwYpKipKEyZM0OrVqxUfH18uRQIAAAAlUeJwu3//frVv3956f/ny5WrVqpXeeecdjRkzRnPmzLGunAAAAABUhBKH2wsXLigoKMh6f8uWLerUqZP1fsuWLXXy5EnHVgcAAADYocThNigoyLq+bW5urvbt26eIiAhr/8WLF+Xi4uL4CgEAAIASKnG47dy5syZMmKBt27YpNjZWlStX1v3332/t//rrr1W3bt1yKRIAAAAoiRIvBTZ16lR1795dDz74oLy8vLR48WK5urpa+xctWqQOHTqUS5EAAABASZQ43FatWlVbt25VVlaWvLy85OzsbNOfnJwsLy8vhxcIAAAAlJTdX+Lg6+tbbLu/v3+ZiwEAAADKosRzbgEAAIBbHeEWAAAApkG4BQAAgGmUKNzec889unDhgqTrX8N75cqVci0KAAAAKI0ShdvDhw/r8uXLkqQpU6bo0qVL5VoUAAAAUBolWi2hWbNmGjBggNq0aSPDMPTaa6/dcNmviRMnOrRAAAAAoKRKFG6TkpI0adIkrVmzRhaLRZ999pkqVSr6UIvFQrgFAABAhSlRuG3YsKGWL18uSXJyctKGDRsUGBhYroUBAAAA9rL7SxwKCgrKow4AAACgzOwOt5L0/fffa/bs2Tp8+LAkKSwsTCNHjlTdunUdWhwAAABgD7vXuV23bp3CwsK0e/duNW3aVE2bNtWuXbt05513KiUlpTxqBAAAAErE7jO3EyZM0OjRo/Xqq68WaR8/frwefvhhhxUHAAAA2MPuM7eHDx/WoEGDirQPHDhQhw4dckhRAAAAQGnYHW6rVaum/fv3F2nfv38/KygAAACgQtk9LWHw4MEaMmSIfvjhB913332SpO3bt2v69OkaM2aMwwsEAAAASsrucPvSSy/J29tbM2fOVGxsrCSpRo0amjx5skaMGOHwAgEAAICSsjvcWiwWjR49WqNHj9bFixclSd7e3g4vDAAAALBXqda5LUSoBQAAwK3E7gvKAAAAgFsV4RYAAACmQbgFAACAadgVbq9du6b27dvr6NGj5VUPAAAAUGp2hVsXFxd9/fXX5VULAAAAUCZ2T0vo06ePFi5cWB61AAAAAGVi91JgeXl5WrRokdavX6/mzZvL09PTpv/11193WHEAAACAPewOt998843uueceSdJ3331n02exWBxTFQAAAFAKdk9L2LRp0w1vGzdutGtb8+bNU9OmTeXj4yMfHx9FRkbqs88+s/ZfvXpVMTExCggIkJeXl3r06KGMjAybbZw4cUJdunRR5cqVFRgYqLFjxyovL8/ewwIAAIAJlHopsGPHjmndunX65ZdfJEmGYdi9jZo1a+rVV1/V3r17tWfPHrVr106PPfaYDh48KEkaPXq0Vq9ereTkZG3ZskWnTp1S9+7drY/Pz89Xly5dlJubqx07dmjx4sVKSkrSxIkTS3tYAAAAuI3ZHW7PnTun9u3bq0GDBurcubNOnz4tSRo0aJBeeOEFu7b1yCOPqHPnzqpfv74aNGigV155RV5eXtq5c6eysrK0cOFCvf7662rXrp2aN2+uxMRE7dixQzt37pQkff755zp06JDee+89NWvWTJ06ddLUqVOVkJCg3Nxcew8NAAAAtzm7w+3o0aPl4uKiEydOqHLlytb2p59+WmvXri11Ifn5+Vq+fLkuX76syMhI7d27V9euXVNUVJR1TKNGjVS7dm2lpqZKklJTUxUeHq6goCDrmOjoaGVnZ1vP/hYnJydH2dnZNjcAAADc/uy+oOzzzz/XunXrVLNmTZv2+vXr68cff7S7gAMHDigyMlJXr16Vl5eXVq5cqbCwMO3fv1+urq7y8/OzGR8UFKT09HRJUnp6uk2wLewv7LuR+Ph4TZkyxe5aAQAAcGuz+8zt5cuXbc7YFjp//rzc3NzsLqBhw4bav3+/du3apaFDh6pfv346dOiQ3duxR2xsrLKysqy3kydPluv+AAAAcHPYHW7vv/9+LVmyxHrfYrGooKBAM2bM0EMPPWR3Aa6urqpXr56aN2+u+Ph43XXXXXrjjTcUHBys3NxcZWZm2ozPyMhQcHCwJCk4OLjI6gmF9wvHFMfNzc26QkPhDQAAALc/u8PtjBkz9Pbbb6tTp07Kzc3VuHHj1KRJE23dulXTp08vc0EFBQXKyclR8+bN5eLiog0bNlj7jhw5ohMnTigyMlKSFBkZqQMHDujMmTPWMSkpKfLx8VFYWFiZawEAAMDtxe45t02aNNF3332nt956S97e3rp06ZK6d++umJgYVa9e3a5txcbGqlOnTqpdu7YuXryoZcuWafPmzVq3bp18fX01aNAgjRkzRv7+/vLx8dHw4cMVGRmpiIgISVKHDh0UFhamZ599VjNmzFB6erpefPFFxcTElGqKBAAAAG5vdodbSfL19dXf/va3Mu/8zJkz6tu3r06fPi1fX181bdpU69at08MPPyxJmjVrlpycnNSjRw/l5OQoOjpac+fOtT7e2dlZa9as0dChQxUZGSlPT0/169dPcXFxZa4NAAAAt59ShdsLFy5o4cKFOnz4sCQpLCxMAwYMkL+/v13bWbhw4e/2u7u7KyEhQQkJCTccExISok8//dSu/QIAAMCc7J5zu3XrVtWpU0dz5szRhQsXdOHCBc2ZM0ehoaHaunVredQIAAAAlIjdZ25jYmL09NNPa968eXJ2dpZ0/QsYnn/+ecXExOjAgQMOLxIAAAAoCbvP3B47dkwvvPCCNdhK1+e+jhkzRseOHXNocQAAAIA97A6399xzj3Wu7a8dPnxYd911l0OKAgAAAEqjRNMSvv76a+vPI0aM0MiRI3Xs2DHrklw7d+5UQkKCXn311fKpEgAAACiBEoXbZs2ayWKxyDAMa9u4ceOKjHvmmWf09NNPO646AAAAwA4lCrdpaWnlXQcAAABQZiUKtyEhIeVdBwAAAFBmpfoSh1OnTumLL77QmTNnVFBQYNM3YsQIhxQGAAAA2MvucJuUlKTnnntOrq6uCggIkMVisfZZLBbCLQAAACqM3eH2pZde0sSJExUbGysnJ7tXEgMAAADKjd3p9MqVK+rZsyfBFgAAALccuxPqoEGDlJycXB61AAAAAGVi97SE+Ph4de3aVWvXrlV4eLhcXFxs+l9//XWHFQcAAADYo1Thdt26dWrYsKEkFbmgDAAAAKgodofbmTNnatGiRerfv385lAMAAACUnt1zbt3c3NS6devyqAUAAAAoE7vD7ciRI/Xmm2+WRy0AAABAmdg9LWH37t3auHGj1qxZozvvvLPIBWUfffSRw4oDAAAA7GF3uPXz81P37t3LoxYAAACgTOwOt4mJieVRBwAAAFBmfM0YAAAATMPuM7ehoaG/u57tDz/8UKaCAAAAgNKyO9yOGjXK5v61a9f073//W2vXrtXYsWMdVRcAAABgN7vD7ciRI4ttT0hI0J49e8pcEAAAAFBaDptz26lTJ/3zn/901OYAAAAAuzks3K5YsUL+/v6O2hwAAABgN7unJdx99902F5QZhqH09HSdPXtWc+fOdWhxAAAAgD3sDrfdunWzue/k5KRq1aqpbdu2atSokaPqAgAAAOxmd7idNGlSedQBAAAAlBlf4gAAAADTKPGZWycnp9/98gZJslgsysvLK3NRAAAAQGmUONyuXLnyhn2pqamaM2eOCgoKHFIUAAAAUBolDrePPfZYkbYjR45owoQJWr16tXr37q24uDiHFgcAAADYo1Rzbk+dOqXBgwcrPDxceXl52r9/vxYvXqyQkBBH1wcAAACUmF3hNisrS+PHj1e9evV08OBBbdiwQatXr1aTJk3Kqz4AAACgxEo8LWHGjBmaPn26goOD9f777xc7TQEAAACoSCUOtxMmTJCHh4fq1aunxYsXa/HixcWO++ijjxxWHAAAAGCPEofbvn37/uFSYAAAAEBFKnG4TUpKKscyAAAAgLLjG8oAAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGhUabuPj49WyZUt5e3srMDBQ3bp105EjR2zGXL16VTExMQoICJCXl5d69OihjIwMmzEnTpxQly5dVLlyZQUGBmrs2LHKy8u7mYcCAACAW0CFhtstW7YoJiZGO3fuVEpKiq5du6YOHTro8uXL1jGjR4/W6tWrlZycrC1btujUqVPq3r27tT8/P19dunRRbm6uduzYocWLFyspKUkTJ06siEMCAABABSrxOrflYe3atTb3k5KSFBgYqL179+qBBx5QVlaWFi5cqGXLlqldu3aSpMTERDVu3Fg7d+5URESEPv/8cx06dEjr169XUFCQmjVrpqlTp2r8+PGaPHmyXF1dK+LQAAAAUAFuqTm3WVlZkiR/f39J0t69e3Xt2jVFRUVZxzRq1Ei1a9dWamqqJCk1NVXh4eEKCgqyjomOjlZ2drYOHjxY7H5ycnKUnZ1tcwMAAMDt75YJtwUFBRo1apRat26tJk2aSJLS09Pl6uoqPz8/m7FBQUFKT0+3jvl1sC3sL+wrTnx8vHx9fa23WrVqOfhoAAAAUBFumXAbExOjb775RsuXLy/3fcXGxiorK8t6O3nyZLnvEwAAAOWvQufcFho2bJjWrFmjrVu3qmbNmtb24OBg5ebmKjMz0+bsbUZGhoKDg61jdu/ebbO9wtUUCsf8lpubm9zc3Bx8FAAAAKhoFXrm1jAMDRs2TCtXrtTGjRsVGhpq09+8eXO5uLhow4YN1rYjR47oxIkTioyMlCRFRkbqwIEDOnPmjHVMSkqKfHx8FBYWdnMOBAAAALeECj1zGxMTo2XLlunjjz+Wt7e3dY6sr6+vPDw85Ovrq0GDBmnMmDHy9/eXj4+Phg8frsjISEVEREiSOnTooLCwMD377LOaMWOG0tPT9eKLLyomJoazswAAAP9jKjTczps3T5LUtm1bm/bExET1799fkjRr1iw5OTmpR48eysnJUXR0tObOnWsd6+zsrDVr1mjo0KGKjIyUp6en+vXrp7i4uJt1GAAAALhFVGi4NQzjD8e4u7srISFBCQkJNxwTEhKiTz/91JGlAQAA4DZ0y6yWAAAAAJQV4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmUaHhduvWrXrkkUdUo0YNWSwWrVq1yqbfMAxNnDhR1atXl4eHh6KionT06FGbMefPn1fv3r3l4+MjPz8/DRo0SJcuXbqJRwEAAIBbRYWG28uXL+uuu+5SQkJCsf0zZszQnDlzNH/+fO3atUuenp6Kjo7W1atXrWN69+6tgwcPKiUlRWvWrNHWrVs1ZMiQm3UIAAAAuIVUqsidd+rUSZ06dSq2zzAMzZ49Wy+++KIee+wxSdKSJUsUFBSkVatWqWfPnjp8+LDWrl2rL7/8Ui1atJAkvfnmm+rcubNee+011ahR46YdCwAAACreLTvnNi0tTenp6YqKirK2+fr6qlWrVkpNTZUkpaamys/PzxpsJSkqKkpOTk7atWvXDbedk5Oj7OxsmxsAAABuf7dsuE1PT5ckBQUF2bQHBQVZ+9LT0xUYGGjTX6lSJfn7+1vHFCc+Pl6+vr7WW61atRxcPQAAACrCLRtuy1NsbKyysrKst5MnT1Z0SQAAAHCAWzbcBgcHS5IyMjJs2jMyMqx9wcHBOnPmjE1/Xl6ezp8/bx1THDc3N/n4+NjcAAAAcPu7ZcNtaGiogoODtWHDBmtbdna2du3apcjISElSZGSkMjMztXfvXuuYjRs3qqCgQK1atbrpNQMAAKBiVehqCZcuXdKxY8es99PS0rR//375+/urdu3aGjVqlF5++WXVr19foaGheumll1SjRg1169ZNktS4cWN17NhRgwcP1vz583Xt2jUNGzZMPXv2ZKUEAACA/0EVGm737Nmjhx56yHp/zJgxkqR+/fopKSlJ48aN0+XLlzVkyBBlZmaqTZs2Wrt2rdzd3a2PWbp0qYYNG6b27dvLyclJPXr00Jw5c276sQAAAKDiVWi4bdu2rQzDuGG/xWJRXFyc4uLibjjG399fy5YtK4/yAAAAcJu5ZefcAgAAAPYi3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0TBNuExISVKdOHbm7u6tVq1bavXt3RZcEAACAm8wU4faDDz7QmDFjNGnSJO3bt0933XWXoqOjdebMmYouDQAAADeRKcLt66+/rsGDB2vAgAEKCwvT/PnzVblyZS1atKiiSwMAAMBNVKmiCyir3Nxc7d27V7GxsdY2JycnRUVFKTU1tdjH5OTkKCcnx3o/KytLkpSdne2wuvJzfnHYtgBHceRrvLzw3sGt5nZ430i8d3DrcfR7p3B7hmH87rjbPtz+/PPPys/PV1BQkE17UFCQvv3222IfEx8frylTphRpr1WrVrnUCNwqfN/8c0WXANx2eN8ApVNe752LFy/K19f3hv23fbgtjdjYWI0ZM8Z6v6CgQOfPn1dAQIAsFksFVobfys7OVq1atXTy5En5+PhUdDnAbYP3DmA/3je3NsMwdPHiRdWoUeN3x9324bZq1apydnZWRkaGTXtGRoaCg4OLfYybm5vc3Nxs2vz8/MqrRDiAj48Pv2iAUuC9A9iP982t6/fO2Ba67S8oc3V1VfPmzbVhwwZrW0FBgTZs2KDIyMgKrAwAAAA3221/5laSxowZo379+qlFixa69957NXv2bF2+fFkDBgyo6NIAAABwE5ki3D799NM6e/asJk6cqPT0dDVr1kxr164tcpEZbj9ubm6aNGlSkWkkAH4f7x3AfrxvzMFi/NF6CgAAAMBt4rafcwsAAAAUItwCAADANAi3AAAAMA3CLQAAAEyDcIsS6d+/vywWi1599VWb9lWrVlm/1W3z5s2yWCzF3tLT063b6datW5HtFz42MzNTbdu2veF2LBaL2rZtK0mqU6eOta1y5coKDw/XP/7xj2Lrf//99+Xs7KyYmJjf3TdQHgrfPxaLRa6urqpXr57i4uKUl5cnScrPz9esWbMUHh4ud3d3ValSRZ06ddL27dtttpOfn69XX31VjRo1koeHh/z9/dWqVSub1/2v32O/9z6yWCyaPHmyjh8/LovFov3792vv3r2yWCzauXNnscfRvn17de/evcgx/frWsWPHcngG8b/CUZ810vVvG3vppZd05513ysPDQwEBAWrZsqVmzJihCxcuFNl3cZ8T9nwezZ49W7m5uapatWqR+gtNnTpVQUFBunbtmpKSkordpru7e1mfxv95plgKDDeHu7u7pk+frueee05VqlS54bgjR44U+WaXwMDAEu/no48+Um5uriTp5MmTuvfee7V+/Xrdeeedkq5/cUehuLg4DR48WFeuXFFycrIGDx6s//u//1OnTp1strlw4UKNGzdOCxYs0MyZM/nlgZuuY8eOSkxMVE5Ojj799FPFxMTIxcVFEyZMUM+ePbV+/Xr9/e9/V/v27ZWdna2EhAS1bdtWycnJ1rA6ZcoULViwQG+99ZZatGih7Oxs7dmzp9gPakk6ffq09ecPPvhAEydO1JEjR6xtXl5e+vnnn633mzdvrrvuukuLFi1SRESEzbaOHz+uTZs2afXq1UWO6ddYQgll5YjPmvPnz6tNmzbKzs7W1KlT1bx5c/n6+urIkSNKTEzUsmXLipzsKO5zwp7Po8L7ffr0UWJioiZMmGDTZxiGkpKS1LdvX7m4uEi6/k1ov35PSrKGeJQe4RYlFhUVpWPHjik+Pl4zZsy44bjAwMAyfZ2xv7+/9eerV69KkgICAor9OmVvb29r+/jx4zVjxgylpKTYhNu0tDTt2LFD//znP7Vp0yZ99NFHeuaZZ0pdH1Aabm5u1tfq0KFDtXLlSn3yySe64447tGLFCn3yySd65JFHrOPffvttnTt3Tn/605/08MMPy9PTU5988omef/55Pfnkk9Zxd9111w33+ev3jK+vrywWS5H30a/DrSQNGjRIL774ombPnq3KlStb25OSklS9enWbM7O/PibAURzxWfPXv/5VJ06c0HfffacaNWpY20NCQtShQwf9dhXUG31O2PN5VGjQoEF644039MUXX6hNmzbW9i1btuiHH37QoEGDrG3FvSdRdkxLQIk5Oztr2rRpevPNN/XTTz9VdDk2CgoK9M9//lMXLlwo8j/pxMREdenSRb6+vurTp48WLlxYQVUC/+Xh4aHc3FwtW7ZMDRo0sAm2hV544QWdO3dOKSkpkq6H1Y0bN+rs2bPlVlfv3r2Vk5OjFStWWNsMw9DixYvVv39/OTs7l9u+AansnzUFBQX64IMP1KdPH5tg+2u/PTvqyM+J8PBwtWzZUosWLSqyj/vuu0+NGjUq9bZRMoRb2OXxxx9Xs2bNNGnSpBuOqVmzpry8vKy3wj/flIfx48fLy8tLbm5ueuKJJ1SlShX96U9/svYXFBQoKSlJffr0kST17NlTX3zxhdLS0sqtJuD3GIah9evXa926dWrXrp2+++47NW7cuNixhe3fffedJOn111/X2bNnFRwcrKZNm+rPf/6zPvvsM4fW5+/vr8cff9zmg3nTpk06fvx4ka80X7Nmjc173cvLS9OmTXNoPfjfVJbPmrNnzyozM1MNGza0Gd+8eXPr2F69elnby+NzYtCgQUpOTtalS5ckSRcvXtSKFSs0cOBAm3FZWVlF3kO/nVYH+zEtAXabPn262rVrp7/85S/F9m/btk3e3t7W+4Vzi8rD2LFj1b9/f50+fVpjx47V888/r3r16ln7U1JSdPnyZXXu3FmSVLVqVT388MNatGiRpk6dWm51Ab9VGASvXbumgoICPfPMM5o8ebLWrFlT5E+kNxIWFqZvvvlGe/fu1fbt27V161Y98sgj6t+//w0vpiyNgQMHKjo6Wt9//73q1q2rRYsW6cEHH7R5b0nSQw89pHnz5tm0/frPuEBZOPqzZuXKlcrNzdX48eP1yy+/WNvL43OiV69eGj16tD788EMNHDhQH3zwgZycnPT000/bjPP29ta+ffts2jw8PEq1T/wX4RZ2e+CBBxQdHa3Y2Fj179+/SH9oaOgN50H5+Pjoxx9/LNKemZkpZ2dneXp62lVL1apVVa9ePdWrV0/JyckKDw9XixYtFBYWJun6BQLnz5+3+WVRUFCgr7/+WlOmTJGTE3+8wM1RGARdXV1Vo0YNVap0/ddvgwYNdPjw4WIfU9jeoEEDa5uTk5Natmypli1batSoUXrvvff07LPP6m9/+5tCQ0MdUmv79u1Vu3ZtJSUlaezYsfroo4+0YMGCIuM8PT2LBF7AUUr7WVOtWjX5+fkVuVCrdu3akq4Hyl+vjlMenxM+Pj564oknlJiYqIEDByoxMVFPPfWUvLy8bMY5OTnxHioHfLKjVF599VWtXr1aqampdj2uYcOGOnjwoHJycmza9+3bp9DQ0DKd5a1Vq5aefvppxcbGSpLOnTunjz/+WMuXL9f+/futt3//+9+6cOGCPv/881LvC7BXYRCsXbu2NdhK1/8EevToUZtVCArNnDlTAQEBevjhh2+43cL/yF2+fNlhtTo5OWnAgAFavHixli1bJldXVz3xxBMO2z5QUqX5rHFyctJTTz2l9957T6dOnfrdseX5OTFo0CB98cUXWrNmjXbs2GFzIRnKF2duUSrh4eHq3bu35syZU6TvzJkz1qtKCwUEBMjFxUW9e/dWXFyc+vbtq3HjxsnX11dbt27V7Nmzf/eq2JIaOXKkmjRpoj179uiLL75QQECAnnrqqSIXD3Tu3FkLFy60ufL7wIEDNn/islgsv3slOuAIPXv2VHJysvr161dkKbBPPvlEycnJ1r9oPPHEE2rdurXuu+8+BQcHKy0tTbGxsWrQoIHDL1IZMGCA4uLi9Ne//lW9evUq9k+lOTk5NuuKSlKlSpVUtWpVh9aC/12l/ayZNm2aNm/erHvvvVdxcXFq0aKFPD099fXXXys1NVVNmjSRJL377rt2fU7Y44EHHlC9evXUt29fNWrUSPfdd1+RMYZhFHkPSddXguAvi6VHuEWpxcXF6YMPPijS/ttJ/JKUmpqqiIgI+fn5adu2bZowYYIeffRRZWVlqV69enr99dcd8r/asLAwdejQQRMnTtRPP/2kxx9/vNg1A3v06KFnn33WZhmkBx54wGaMs7OzdZF9oLxYLBZ9+OGHmj17tmbNmqXnn39e7u7uioyM1ObNm9W6dWvr2OjoaL3//vuKj49XVlaWgoOD1a5dO02ePNnmbLAj1K5dW1FRUfr888+LXARTaO3atapevbpNW8OGDfXtt986tBb8byvNZ01AQIB2796t6dOn6+9//7vS0tLk5OSk+vXr6+mnn9aoUaMkSYsWLSrR50Rp/sNmsVg0cOBA/fWvf7X+RfG3srOzi7yHpOtrVLNEWOlZjJJeyQAAAADc4jjnDQAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAmkpSUJD8/vzJvx2KxaNWqVWXeDgDcbIRbALjF9O/fX926davoMgDgtkS4BQAAgGkQbgHgNvL6668rPDxcnp6eqlWrlp5//nldunSpyLhVq1apfv36cnd3V3R0tE6ePGnT//HHH+uee+6Ru7u77rjjDk2ZMkV5eXk36zAAoNwQbgHgNuLk5KQ5c+bo4MGDWrx4sTZu3Khx48bZjLly5YpeeeUVLVmyRNu3b1dmZqZ69uxp7d+2bZv69u2rkSNH6tChQ1qwYIGSkpL0yiuv3OzDAQCHsxiGYVR0EQCA/+rfv78yMzNLdEHXihUr9Oc//1k///yzpOsXlA0YMEA7d+5Uq1atJEnffvutGjdurF27dunee+9VVFSU2rdvr9jYWOt23nvvPY0bN06nTp2SdP2CspUrVzL3F8Btp1JFFwAAKLn169crPj5e3377rbKzs5WXl6erV6/qypUrqly5siSpUqVKatmypfUxjRo1kp+fnw4fPqx7771XX331lbZv325zpjY/P7/IdgDgdkS4BYDbxPHjx9W1a1cNHTpUr7zyivz9/fXFF19o0KBBys3NLXEovXTpkqZMmaLu3bsX6XN3d3d02QBwUxFuAeA2sXfvXhUUFGjmzJlycrp+ycSHH35YZFxeXp727Nmje++9V5J05MgRZWZmqnHjxpKke+65R0eOHFG9evVuXvEAcJMQbgHgFpSVlaX9+/fbtFWtWlXXrl3Tm2++qUceeUTbt2/X/PnzizzWxcVFw4cP15w5c1SpUiUNGzZMERER1rA7ceJEde3aVbVr19YTTzwhJycnffXVV/rmm2/08ssv34zDA4Byw2oJAHAL2rx5s+6++26b27vvvqvXX39d06dPV5MmTbR06VLFx8cXeWzlypU1fvx4PfPMM2rdurW8vLz0wQcfWPujo6O1Zs0aff7552rZsqUiIiI0a9YshYSE3MxDBIBywWoJAAAAMA3O3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATOP/ASAxEgJkMlUFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf1pc8ymuXWL",
        "outputId": "4d492a6d-b918-42b9-a655-643e0d108593"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2548"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_enhanced_dense_model():\n",
        "    inputs = tf.keras.Input(shape=(2548,))\n",
        "\n",
        "    # Dense layers with BatchNorm and Dropout\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create & compile\n",
        "model = create_enhanced_dense_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "YlMhTd8hoCHe",
        "outputId": "f07938a2-f6ad-4a80-cfec-7672644072b2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_936\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_936\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_937 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2548\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5616 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,305,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3743        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3743 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5617 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3744        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3744 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5618 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3745        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3745 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5619 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3746        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3746 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5620 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5621 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_937 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2548</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5616 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,305,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3743        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3743 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5617 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3744        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3744 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5618 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3745        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3745 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5619 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3746        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3746 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5620 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5621 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,485,763\u001b[0m (5.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,485,763</span> (5.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,483,843\u001b[0m (5.66 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,483,843</span> (5.66 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 📈 Train Model\n",
        "# ========================\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOuMU6xfoGce",
        "outputId": "b4c348ce-97de-4cc1-f879-b702207ef7c6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.5482 - loss: 1.0901 - val_accuracy: 0.7188 - val_loss: 1.1071\n",
            "Epoch 2/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4857 - val_accuracy: 0.8594 - val_loss: 0.3357\n",
            "Epoch 3/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.3934 - val_accuracy: 0.9219 - val_loss: 0.1676\n",
            "Epoch 4/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3042 - val_accuracy: 0.9271 - val_loss: 0.1626\n",
            "Epoch 5/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9080 - loss: 0.2409 - val_accuracy: 0.9375 - val_loss: 0.1576\n",
            "Epoch 6/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.2624 - val_accuracy: 0.9323 - val_loss: 0.1634\n",
            "Epoch 7/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2461 - val_accuracy: 0.9323 - val_loss: 0.1516\n",
            "Epoch 8/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2268 - val_accuracy: 0.9271 - val_loss: 0.1369\n",
            "Epoch 9/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.2018 - val_accuracy: 0.9531 - val_loss: 0.1415\n",
            "Epoch 10/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2054 - val_accuracy: 0.9427 - val_loss: 0.1044\n",
            "Epoch 11/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.2021 - val_accuracy: 0.9427 - val_loss: 0.1206\n",
            "Epoch 12/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9373 - loss: 0.1758 - val_accuracy: 0.9688 - val_loss: 0.1109\n",
            "Epoch 13/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.1756 - val_accuracy: 0.9740 - val_loss: 0.0867\n",
            "Epoch 14/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1539 - val_accuracy: 0.9635 - val_loss: 0.0924\n",
            "Epoch 15/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1266 - val_accuracy: 0.9635 - val_loss: 0.0922\n",
            "Epoch 16/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.1419 - val_accuracy: 0.9635 - val_loss: 0.0996\n",
            "Epoch 17/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9544 - loss: 0.1207 - val_accuracy: 0.9479 - val_loss: 0.1132\n",
            "Epoch 18/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1415 - val_accuracy: 0.9688 - val_loss: 0.0947\n",
            "Epoch 19/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9589 - loss: 0.1217 - val_accuracy: 0.9688 - val_loss: 0.0955\n",
            "Epoch 20/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9697 - loss: 0.0964 - val_accuracy: 0.9740 - val_loss: 0.0669\n",
            "Epoch 21/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.0790 - val_accuracy: 0.9740 - val_loss: 0.0766\n",
            "Epoch 22/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9618 - loss: 0.1048 - val_accuracy: 0.9427 - val_loss: 0.1225\n",
            "Epoch 23/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0677 - val_accuracy: 0.9635 - val_loss: 0.1002\n",
            "Epoch 24/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.0868 - val_accuracy: 0.9844 - val_loss: 0.0509\n",
            "Epoch 25/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.0859 - val_accuracy: 0.9844 - val_loss: 0.0453\n",
            "Epoch 26/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9766 - loss: 0.0715 - val_accuracy: 0.9792 - val_loss: 0.0682\n",
            "Epoch 27/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.0657 - val_accuracy: 0.9740 - val_loss: 0.0475\n",
            "Epoch 28/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0559 - val_accuracy: 0.9792 - val_loss: 0.0521\n",
            "Epoch 29/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.0713 - val_accuracy: 0.9844 - val_loss: 0.0739\n",
            "Epoch 30/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0670 - val_accuracy: 0.9635 - val_loss: 0.0912\n",
            "Epoch 31/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9704 - loss: 0.0900 - val_accuracy: 0.9792 - val_loss: 0.0657\n",
            "Epoch 32/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0701 - val_accuracy: 0.9740 - val_loss: 0.0719\n",
            "Epoch 33/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0466 - val_accuracy: 0.9635 - val_loss: 0.0927\n",
            "Epoch 34/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0788 - val_accuracy: 0.9688 - val_loss: 0.0818\n",
            "Epoch 35/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.0740 - val_accuracy: 0.9740 - val_loss: 0.1094\n",
            "Epoch 36/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0471 - val_accuracy: 0.9583 - val_loss: 0.1104\n",
            "Epoch 37/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.0840 - val_accuracy: 0.9688 - val_loss: 0.0590\n",
            "Epoch 38/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0639 - val_accuracy: 0.9740 - val_loss: 0.0746\n",
            "Epoch 39/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0501 - val_accuracy: 0.9740 - val_loss: 0.1007\n",
            "Epoch 40/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.0441 - val_accuracy: 0.9635 - val_loss: 0.1024\n",
            "Epoch 41/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.0406 - val_accuracy: 0.9792 - val_loss: 0.0781\n",
            "Epoch 42/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0745 - val_accuracy: 0.9792 - val_loss: 0.0871\n",
            "Epoch 43/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0287 - val_accuracy: 0.9740 - val_loss: 0.0776\n",
            "Epoch 44/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0867 - val_accuracy: 0.9792 - val_loss: 0.0901\n",
            "Epoch 45/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0480 - val_accuracy: 0.9792 - val_loss: 0.0587\n",
            "Epoch 46/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0402 - val_accuracy: 0.9740 - val_loss: 0.0899\n",
            "Epoch 47/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9749 - loss: 0.0793 - val_accuracy: 0.9688 - val_loss: 0.0846\n",
            "Epoch 48/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0378 - val_accuracy: 0.9688 - val_loss: 0.0964\n",
            "Epoch 49/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0719 - val_accuracy: 0.9792 - val_loss: 0.0986\n",
            "Epoch 50/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0388 - val_accuracy: 0.9740 - val_loss: 0.0633\n",
            "Epoch 51/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0425 - val_accuracy: 0.9792 - val_loss: 0.1219\n",
            "Epoch 52/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0352 - val_accuracy: 0.9740 - val_loss: 0.0886\n",
            "Epoch 53/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0247 - val_accuracy: 0.9740 - val_loss: 0.0689\n",
            "Epoch 54/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0403 - val_accuracy: 0.9792 - val_loss: 0.0890\n",
            "Epoch 55/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0280 - val_accuracy: 0.9740 - val_loss: 0.0955\n",
            "Epoch 56/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 0.0398 - val_accuracy: 0.9583 - val_loss: 0.1287\n",
            "Epoch 57/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0455 - val_accuracy: 0.9792 - val_loss: 0.0725\n",
            "Epoch 58/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0408 - val_accuracy: 0.9740 - val_loss: 0.1188\n",
            "Epoch 59/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.9792 - val_loss: 0.0793\n",
            "Epoch 60/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0510 - val_accuracy: 0.9792 - val_loss: 0.0656\n",
            "Epoch 61/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0337 - val_accuracy: 0.9688 - val_loss: 0.1072\n",
            "Epoch 62/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0453 - val_accuracy: 0.9740 - val_loss: 0.0855\n",
            "Epoch 63/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0152 - val_accuracy: 0.9792 - val_loss: 0.0621\n",
            "Epoch 64/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0436 - val_accuracy: 0.9688 - val_loss: 0.0886\n",
            "Epoch 65/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0307 - val_accuracy: 0.9792 - val_loss: 0.0495\n",
            "Epoch 66/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0310 - val_accuracy: 0.9792 - val_loss: 0.0624\n",
            "Epoch 67/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0191 - val_accuracy: 0.9740 - val_loss: 0.0550\n",
            "Epoch 68/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0343 - val_accuracy: 0.9740 - val_loss: 0.0788\n",
            "Epoch 69/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0259 - val_accuracy: 0.9792 - val_loss: 0.0415\n",
            "Epoch 70/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0197 - val_accuracy: 0.9792 - val_loss: 0.0682\n",
            "Epoch 71/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0376 - val_accuracy: 0.9740 - val_loss: 0.0762\n",
            "Epoch 72/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0405 - val_accuracy: 0.9688 - val_loss: 0.0778\n",
            "Epoch 73/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0271 - val_accuracy: 0.9844 - val_loss: 0.0713\n",
            "Epoch 74/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9815 - loss: 0.0582 - val_accuracy: 0.9896 - val_loss: 0.0680\n",
            "Epoch 75/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0500 - val_accuracy: 0.9948 - val_loss: 0.0511\n",
            "Epoch 76/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0273 - val_accuracy: 0.9844 - val_loss: 0.0596\n",
            "Epoch 77/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0253 - val_accuracy: 0.9740 - val_loss: 0.0702\n",
            "Epoch 78/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0178 - val_accuracy: 0.9740 - val_loss: 0.0792\n",
            "Epoch 79/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0205 - val_accuracy: 0.9792 - val_loss: 0.1378\n",
            "Epoch 80/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0286 - val_accuracy: 0.9896 - val_loss: 0.0582\n",
            "Epoch 81/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0208 - val_accuracy: 0.9844 - val_loss: 0.0656\n",
            "Epoch 82/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0381 - val_accuracy: 0.9844 - val_loss: 0.0649\n",
            "Epoch 83/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0437 - val_accuracy: 0.9740 - val_loss: 0.0950\n",
            "Epoch 84/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0359 - val_accuracy: 0.9792 - val_loss: 0.0788\n",
            "Epoch 85/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0460 - val_accuracy: 0.9740 - val_loss: 0.1186\n",
            "Epoch 86/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0507 - val_accuracy: 0.9740 - val_loss: 0.0860\n",
            "Epoch 87/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0409 - val_accuracy: 0.9740 - val_loss: 0.0924\n",
            "Epoch 88/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0331 - val_accuracy: 0.9740 - val_loss: 0.0974\n",
            "Epoch 89/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0251 - val_accuracy: 0.9688 - val_loss: 0.0728\n",
            "Epoch 90/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0122 - val_accuracy: 0.9792 - val_loss: 0.0911\n",
            "Epoch 91/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0110 - val_accuracy: 0.9792 - val_loss: 0.1027\n",
            "Epoch 92/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0171 - val_accuracy: 0.9740 - val_loss: 0.0979\n",
            "Epoch 93/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 0.9844 - val_loss: 0.0939\n",
            "Epoch 94/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0233 - val_accuracy: 0.9740 - val_loss: 0.1659\n",
            "Epoch 95/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0410 - val_accuracy: 0.9792 - val_loss: 0.0745\n",
            "Epoch 96/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0357 - val_accuracy: 0.9844 - val_loss: 0.0514\n",
            "Epoch 97/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0187 - val_accuracy: 0.9792 - val_loss: 0.0787\n",
            "Epoch 98/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0136 - val_accuracy: 0.9740 - val_loss: 0.0676\n",
            "Epoch 99/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0119 - val_accuracy: 0.9792 - val_loss: 0.0507\n",
            "Epoch 100/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0156 - val_accuracy: 0.9740 - val_loss: 0.0834\n",
            "Epoch 101/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0183 - val_accuracy: 0.9844 - val_loss: 0.0342\n",
            "Epoch 102/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0244 - val_accuracy: 0.9844 - val_loss: 0.0584\n",
            "Epoch 103/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0223 - val_accuracy: 0.9896 - val_loss: 0.0640\n",
            "Epoch 104/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0527 - val_accuracy: 0.9740 - val_loss: 0.0534\n",
            "Epoch 105/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0487 - val_accuracy: 0.9740 - val_loss: 0.0552\n",
            "Epoch 106/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0429 - val_accuracy: 0.9844 - val_loss: 0.0589\n",
            "Epoch 107/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0108 - val_accuracy: 0.9896 - val_loss: 0.0335\n",
            "Epoch 108/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0274 - val_accuracy: 0.9635 - val_loss: 0.0791\n",
            "Epoch 109/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0263 - val_accuracy: 0.9792 - val_loss: 0.1011\n",
            "Epoch 110/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0196 - val_accuracy: 0.9896 - val_loss: 0.0429\n",
            "Epoch 111/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0366 - val_accuracy: 0.9896 - val_loss: 0.0368\n",
            "Epoch 112/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0306 - val_accuracy: 0.9792 - val_loss: 0.0661\n",
            "Epoch 113/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0423 - val_accuracy: 0.9740 - val_loss: 0.0667\n",
            "Epoch 114/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0196 - val_accuracy: 0.9896 - val_loss: 0.0392\n",
            "Epoch 115/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0245 - val_accuracy: 0.9792 - val_loss: 0.0829\n",
            "Epoch 116/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0298 - val_accuracy: 0.9948 - val_loss: 0.0488\n",
            "Epoch 117/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0243 - val_accuracy: 0.9844 - val_loss: 0.0672\n",
            "Epoch 118/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0204 - val_accuracy: 0.9740 - val_loss: 0.0979\n",
            "Epoch 119/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0286 - val_accuracy: 0.9740 - val_loss: 0.0924\n",
            "Epoch 120/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0328 - val_accuracy: 0.9740 - val_loss: 0.0416\n",
            "Epoch 121/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0150 - val_accuracy: 0.9844 - val_loss: 0.0592\n",
            "Epoch 122/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0064 - val_accuracy: 0.9792 - val_loss: 0.0528\n",
            "Epoch 123/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0215 - val_accuracy: 0.9844 - val_loss: 0.0500\n",
            "Epoch 124/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0095 - val_accuracy: 0.9635 - val_loss: 0.0973\n",
            "Epoch 125/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0231 - val_accuracy: 0.9844 - val_loss: 0.0479\n",
            "Epoch 126/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0198 - val_accuracy: 0.9688 - val_loss: 0.0976\n",
            "Epoch 127/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0106 - val_accuracy: 0.9688 - val_loss: 0.1460\n",
            "Epoch 128/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0156 - val_accuracy: 0.9896 - val_loss: 0.0446\n",
            "Epoch 129/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 0.0369 - val_accuracy: 0.9740 - val_loss: 0.0880\n",
            "Epoch 130/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0216 - val_accuracy: 0.9792 - val_loss: 0.0669\n",
            "Epoch 131/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0233 - val_accuracy: 0.9635 - val_loss: 0.1363\n",
            "Epoch 132/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0273 - val_accuracy: 0.9740 - val_loss: 0.1226\n",
            "Epoch 133/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0556 - val_accuracy: 0.9792 - val_loss: 0.0601\n",
            "Epoch 134/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0118 - val_accuracy: 0.9792 - val_loss: 0.0885\n",
            "Epoch 135/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.9844 - val_loss: 0.0610\n",
            "Epoch 136/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0675 - val_accuracy: 0.9844 - val_loss: 0.0540\n",
            "Epoch 137/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0222 - val_accuracy: 0.9792 - val_loss: 0.0596\n",
            "Epoch 138/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0108 - val_accuracy: 0.9792 - val_loss: 0.0760\n",
            "Epoch 139/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0100 - val_accuracy: 0.9792 - val_loss: 0.0758\n",
            "Epoch 140/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0134 - val_accuracy: 0.9792 - val_loss: 0.0633\n",
            "Epoch 141/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0151 - val_accuracy: 0.9844 - val_loss: 0.0674\n",
            "Epoch 142/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0167 - val_accuracy: 0.9688 - val_loss: 0.1142\n",
            "Epoch 143/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0281 - val_accuracy: 0.9792 - val_loss: 0.0671\n",
            "Epoch 144/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0161 - val_accuracy: 0.9792 - val_loss: 0.0914\n",
            "Epoch 145/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.9792 - val_loss: 0.0457\n",
            "Epoch 146/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0178 - val_accuracy: 0.9740 - val_loss: 0.0896\n",
            "Epoch 147/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0325 - val_accuracy: 0.9844 - val_loss: 0.0618\n",
            "Epoch 148/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0266 - val_accuracy: 0.9740 - val_loss: 0.1001\n",
            "Epoch 149/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0213 - val_accuracy: 0.9896 - val_loss: 0.0421\n",
            "Epoch 150/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0309 - val_accuracy: 0.9896 - val_loss: 0.0384\n",
            "Epoch 151/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 0.9896 - val_loss: 0.0579\n",
            "Epoch 152/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0515 - val_accuracy: 0.9792 - val_loss: 0.0470\n",
            "Epoch 153/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0072 - val_accuracy: 0.9792 - val_loss: 0.0663\n",
            "Epoch 154/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.9792 - val_loss: 0.0783\n",
            "Epoch 155/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0206 - val_accuracy: 0.9688 - val_loss: 0.1282\n",
            "Epoch 156/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0173 - val_accuracy: 0.9740 - val_loss: 0.1398\n",
            "Epoch 157/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0197 - val_accuracy: 0.9792 - val_loss: 0.0516\n",
            "Epoch 158/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0202 - val_accuracy: 0.9792 - val_loss: 0.0582\n",
            "Epoch 159/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0300 - val_accuracy: 0.9688 - val_loss: 0.1191\n",
            "Epoch 160/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0227 - val_accuracy: 0.9740 - val_loss: 0.1010\n",
            "Epoch 161/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9844 - val_loss: 0.0658\n",
            "Epoch 162/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0084 - val_accuracy: 0.9792 - val_loss: 0.0857\n",
            "Epoch 163/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.9844 - val_loss: 0.0280\n",
            "Epoch 164/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9740 - val_loss: 0.0984\n",
            "Epoch 165/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0473 - val_accuracy: 0.9844 - val_loss: 0.0579\n",
            "Epoch 166/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0229 - val_accuracy: 0.9792 - val_loss: 0.0663\n",
            "Epoch 167/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.9740 - val_loss: 0.1531\n",
            "Epoch 168/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0072 - val_accuracy: 0.9740 - val_loss: 0.1026\n",
            "Epoch 169/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.9844 - val_loss: 0.0723\n",
            "Epoch 170/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0261 - val_accuracy: 0.9740 - val_loss: 0.1170\n",
            "Epoch 171/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.9844 - val_loss: 0.0303\n",
            "Epoch 172/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0140 - val_accuracy: 0.9844 - val_loss: 0.0709\n",
            "Epoch 173/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0261 - val_accuracy: 0.9740 - val_loss: 0.0921\n",
            "Epoch 174/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9844 - val_loss: 0.0623\n",
            "Epoch 175/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0162 - val_accuracy: 0.9948 - val_loss: 0.0212\n",
            "Epoch 176/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0224 - val_accuracy: 0.9896 - val_loss: 0.0566\n",
            "Epoch 177/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0099 - val_accuracy: 0.9844 - val_loss: 0.0306\n",
            "Epoch 178/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0068 - val_accuracy: 0.9896 - val_loss: 0.0318\n",
            "Epoch 179/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0062 - val_accuracy: 0.9792 - val_loss: 0.0603\n",
            "Epoch 180/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 0.9896 - val_loss: 0.0359\n",
            "Epoch 181/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9844 - val_loss: 0.0505\n",
            "Epoch 182/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9948 - val_loss: 0.0150\n",
            "Epoch 183/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0251 - val_accuracy: 0.9792 - val_loss: 0.0879\n",
            "Epoch 184/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0089 - val_accuracy: 0.9844 - val_loss: 0.0237\n",
            "Epoch 185/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0067 - val_accuracy: 0.9896 - val_loss: 0.0218\n",
            "Epoch 186/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.9479 - val_loss: 0.3815\n",
            "Epoch 187/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0324 - val_accuracy: 0.9635 - val_loss: 0.1799\n",
            "Epoch 188/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 0.0405 - val_accuracy: 0.9792 - val_loss: 0.0804\n",
            "Epoch 189/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0179 - val_accuracy: 0.9792 - val_loss: 0.0735\n",
            "Epoch 190/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0145 - val_accuracy: 0.9688 - val_loss: 0.1405\n",
            "Epoch 191/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0233 - val_accuracy: 0.9896 - val_loss: 0.0574\n",
            "Epoch 192/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9792 - val_loss: 0.1091\n",
            "Epoch 193/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0134 - val_accuracy: 0.9896 - val_loss: 0.0693\n",
            "Epoch 194/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0094 - val_accuracy: 0.9844 - val_loss: 0.0971\n",
            "Epoch 195/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0096 - val_accuracy: 0.9635 - val_loss: 0.1448\n",
            "Epoch 196/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0216 - val_accuracy: 0.9792 - val_loss: 0.0647\n",
            "Epoch 197/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0174 - val_accuracy: 0.9844 - val_loss: 0.0746\n",
            "Epoch 198/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0112 - val_accuracy: 0.9740 - val_loss: 0.0435\n",
            "Epoch 199/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0071 - val_accuracy: 0.9844 - val_loss: 0.0865\n",
            "Epoch 200/200\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0115 - val_accuracy: 0.9740 - val_loss: 0.1825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 💾 Save Model Weights\n",
        "# ========================\n",
        "model.save_weights(\"eeg_model_.weights.h5\")\n",
        "print(\"✅ Model weights saved to eeg_model_weights.h5\")"
      ],
      "metadata": {
        "id": "xayOi7Vxoue8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================\n",
        "# 📊 Evaluate Model\n",
        "# ========================\n",
        "model.load_weights(\"eeg_model_.weights.h5\")\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"✅ Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# ========================\n",
        "# 🔍 Inference Function\n",
        "# ========================\n",
        "label_map = {0: \"NEUTRAL\", 1: \"POSITIVE\", 2: \"NEGATIVE\"}\n",
        "\n",
        "def predict_emotion(eeg_sample, scaled=False):\n",
        "    if not scaled:\n",
        "        eeg_sample = scaler.transform([eeg_sample])\n",
        "    else:\n",
        "        eeg_sample = np.expand_dims(eeg_sample, axis=0)  # add batch dim\n",
        "\n",
        "    pred = model.predict(eeg_sample)\n",
        "    label_idx = np.argmax(pred)\n",
        "    confidence = pred[0][label_idx]\n",
        "    return label_map[label_idx], confidence\n",
        "\n",
        "\n",
        "# Example: Predict from test set\n",
        "sample_idx = 120\n",
        "\n",
        "\n",
        "# Predict\n",
        "pred_label, conf = predict_emotion(x_test[sample_idx], scaled=True)\n",
        "\n",
        "\n",
        "# Get actual label index from one-hot vector\n",
        "actual_label_idx = np.argmax(y_test[sample_idx])\n",
        "\n",
        "# Map to label string\n",
        "actual_label = label_map[actual_label_idx]\n",
        "\n",
        "print(f\"Actual: {actual_label}\")\n",
        "print(f\"Predicted: {pred_label} ({conf*100:.2f}% confidence)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPh3eJTGo-VB",
        "outputId": "2af74a30-c34b-4d1d-f586-46c5601aa4f6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9953 - loss: 0.0204\n",
            "✅ Test Accuracy: 99.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e737266ac00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
            "Actual: POSITIVE\n",
            "Predicted: POSITIVE (100.00% confidence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Module for Mood Detection using EEG data"
      ],
      "metadata": {
        "id": "KDh-JWs6Rvg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from joblib import load\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_enhanced_dense_model():\n",
        "    inputs = tf.keras.Input(shape=(2548,))\n",
        "\n",
        "    # Dense layers with BatchNorm and Dropout\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Load saved scaler\n",
        "def Final_Prediction():\n",
        "  scaler = load('scaler.save')\n",
        "\n",
        "  # Load your new CSV\n",
        "  new_data = pd.read_csv('/content/file.csv')\n",
        "\n",
        "  # Drop label column if exists\n",
        "  if 'label' in new_data.columns:\n",
        "      new_data = new_data.drop(columns=['label'])\n",
        "\n",
        "  X_new = new_data.values\n",
        "\n",
        "  # Scale features\n",
        "  X_new_scaled = scaler.transform(X_new)\n",
        "\n",
        "  # Predict using model\n",
        "  model = create_enhanced_dense_model()\n",
        "  model.load_weights(\"eeg_model_.weights.h5\")\n",
        "  predictions = model.predict(X_new_scaled)\n",
        "\n",
        "  # Decode predictions\n",
        "  predicted_classes = predictions.argmax(axis=1)\n",
        "  label_map = {0: 'NEUTRAL', 1: 'POSITIVE', 2: 'NEGATIVE'}\n",
        "  predicted_labels = [label_map[c] for c in predicted_classes]\n",
        "  return predicted_labels\n",
        "\n",
        "predicted_labels = Final_Prediction()\n",
        "\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_G47vllrOrG",
        "outputId": "0d59a09d-8a63-4b7f-be95-1aa55d294a64"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
            "['NEUTRAL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJkbFvhetwQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDYM77Il0HmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mood detection using face image\n"
      ],
      "metadata": {
        "id": "hkOqi5bYRgo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload Kaggle API token\n",
        "files.upload()  # Upload the kaggle.json file\n",
        "\n",
        "# Step 2: Set up Kaggle API credentials\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "\n",
        "# Step 3: Install Kaggle API\n",
        "!pip install kaggle\n",
        "\n",
        "# Step 4: Download the dataset\n",
        "dataset_identifier = 'jonathanoheix/face-expression-recognition-dataset'\n",
        "download_path = '/content/dataset'\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "!kaggle datasets download -d {dataset_identifier} -p {download_path} --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "2n6TT8sw0Hoi",
        "outputId": "22b518f1-c8fa-4bef-ceab-f7b3a0dd8eb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58eb082b-524b-4e4d-b93d-1a1fe326c761\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58eb082b-524b-4e4d-b93d-1a1fe326c761\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.25.8)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset\n",
            "License(s): unknown\n",
            "Downloading face-expression-recognition-dataset.zip to /content/dataset\n",
            "100% 120M/121M [00:00<00:00, 1.25GB/s]\n",
            "100% 121M/121M [00:00<00:00, 1.25GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Dropout, Flatten, Dense\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Paths - Adjust if necessary\n",
        "data_dir = '/content/dataset/images/images'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "validation_dir = os.path.join(data_dir, 'validation')\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale'\n",
        ")\n",
        "\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(f\"Classes: {class_names}\")\n",
        "\n",
        "# --- Define Residual Block ---\n",
        "def residual_block(x, filters, kernel_size=3, strides=1):\n",
        "    shortcut = x\n",
        "\n",
        "    # First conv layer\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Second conv layer\n",
        "    x = Conv2D(filters, kernel_size, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Shortcut connection with possible downsampling\n",
        "    if strides != 1 or shortcut.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# --- Build Model ---\n",
        "def build_resnet_like_model(input_shape=(48, 48, 1), num_classes=7):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Conv Layer\n",
        "    x = Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual Blocks with increasing filters\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = residual_block(x, 128, strides=2)  # Downsample\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = residual_block(x, 128, strides=2)  # Downsample\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = residual_block(x, 128, strides=2)  # Downsample\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    # Global Max Pooling + Dense layers\n",
        "    x = MaxPooling2D(pool_size=4)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_resnet_like_model()\n",
        "model.load_weights('/content/resnet_.weights.h5')\n",
        "model.summary()\n",
        "\n",
        "# --- Callbacks ---\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6, verbose=1\n",
        ")\n",
        "\n",
        "# --- Train Model ---\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "# --- Evaluation ---\n",
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n",
        "\n",
        "# --- Plot training history ---\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# --- Confusion Matrix on Validation Set ---\n",
        "# Get true labels and predictions\n",
        "val_steps = validation_generator.samples // validation_generator.batch_size + 1\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _ in range(val_steps):\n",
        "    X_val, y_val = next(validation_generator)\n",
        "    preds = model.predict(X_val)\n",
        "    y_true.extend(np.argmax(y_val, axis=1))\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# --- Classification Report ---\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wu0EWxzd0HrT",
        "outputId": "156bae4d-e6f9-4a2b-cc58-a59bda992f16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28821 images belonging to 7 classes.\n",
            "Found 7066 images belonging to 7 classes.\n",
            "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_22       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_22[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │     \u001b[38;5;34m16,512\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_27       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_28       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_28[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_29       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ activation_29[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_30       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ activation_30[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m16,512\u001b[0m │ activation_29[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_31       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ activation_31[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_32       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ activation_32[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ activation_31[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_33       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_33[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m66,048\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │      \u001b[38;5;34m3,591\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_22       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_27       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_28       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_29       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_30       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ activation_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_31       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_32       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ activation_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_33       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,967,623\u001b[0m (7.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,967,623</span> (7.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,962,119\u001b[0m (7.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,962,119</span> (7.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,504\u001b[0m (21.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,504</span> (21.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m 61/451\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:22\u001b[0m 6s/step - accuracy: 0.6595 - loss: 0.8921"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3690623521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# --- Train Model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1501\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('resnet_.weights.h5')"
      ],
      "metadata": {
        "id": "57nmGJ3B3s30"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Module for Mood Detection using Face Images"
      ],
      "metadata": {
        "id": "RJ879w_mR1hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Dropout, Flatten, Dense\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# --- Define Residual Block ---\n",
        "def residual_block(x, filters, kernel_size=3, strides=1):\n",
        "    shortcut = x\n",
        "\n",
        "    # First conv layer\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Second conv layer\n",
        "    x = Conv2D(filters, kernel_size, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Shortcut connection with possible downsampling\n",
        "    if strides != 1 or shortcut.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "def build_resnet_like_model(input_shape=(48, 48, 1), num_classes=7):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Conv Layer\n",
        "    x = Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual Blocks with increasing filters\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = residual_block(x, 128, strides=2)  # Downsample\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = residual_block(x, 128, strides=2)  # Downsample\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = residual_block(x, 128, strides=2)  # Downsample\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    # Global Max Pooling + Dense layers\n",
        "    x = MaxPooling2D(pool_size=4)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def preprocess_image(img_path, target_size=(48,48)):\n",
        "    # Load image in grayscale mode\n",
        "    img = image.load_img(img_path, color_mode='grayscale', target_size=target_size)\n",
        "    # Convert to numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "    # Normalize pixel values to [0,1]\n",
        "    img_array = img_array / 255.0\n",
        "    # Add batch dimension: (48,48,1) -> (1,48,48,1)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "def predict_single_image( img_path, class_names):\n",
        "    # Preprocess image\n",
        "    img = preprocess_image(img_path)\n",
        "\n",
        "    # Predict probabilities\n",
        "    model = build_resnet_like_model()\n",
        "    model.load_weights('/content/resnet_.weights.h5')\n",
        "    preds = model.predict(img)\n",
        "    print(preds)\n",
        "    pred_class_idx = np.argmax(preds)\n",
        "    confidence = preds[0][pred_class_idx]\n",
        "\n",
        "    predicted_label = class_names[pred_class_idx]\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "# 2. Define your class names (must match training classes order)\n",
        "class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        " # replace with your classes\n",
        "\n",
        "# 3. Predict on a new image\n",
        "img_path = '/content/The_joy_of_the_happy_face_by_Rasheedhrasheed.jpg'\n",
        "label = predict_single_image(img_path, class_names)\n",
        "\n",
        "print(f\"Predicted Label: {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAY7Q-1s1LRh",
        "outputId": "477a5b17-5743-4383-9cdb-2cc6067e5415"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "[[4.5457343e-04 5.6263872e-07 1.2919845e-04 9.9761260e-01 1.3169019e-03\n",
            "  3.4277272e-04 1.4354814e-04]]\n",
            "Predicted Label: happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import sys\n",
        "print(sys.version)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2UQxPMp8xms",
        "outputId": "19d3cb28-8df7-4f5f-8723-f3fa08e740ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BjH9Z8hqCFHw",
        "outputId": "d7a4698a-341b-4b51-ef6b-1c4ad3c7b62a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.16.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.2\n",
            "    Uninstalling ml-dtypes-0.3.2:\n",
            "      Successfully uninstalled ml-dtypes-0.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.16.2\n",
            "    Uninstalling tensorboard-2.16.2:\n",
            "      Successfully uninstalled tensorboard-2.16.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.16.2\n",
            "    Uninstalling tensorflow-2.16.2:\n",
            "      Successfully uninstalled tensorflow-2.16.2\n",
            "Successfully installed ml-dtypes-0.5.3 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "227eebc468e34c12b65814149865e379"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYCkqvotCU4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}